{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flying-colonial",
   "metadata": {},
   "source": [
    "# NLP_GoingDeeper | P07.BERT\n",
    "---\n",
    "\n",
    "\n",
    "1. Tokenizer 준비\n",
    "2. 데이터 전처리 (1) MASK 생성\n",
    "3. 데이터 전처리 (2) NSP pair 생성\n",
    "4. 데이터 전처리 (3) 데이터셋 완성\n",
    "5. BERT 모델 구현\n",
    "6. pretrain 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "favorite-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/bert_pretrain/data/kowiki.txt': File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ~/aiffel/bert_pretrain/data\n",
    "! mkdir -p ~/aiffel/bert_pretrain/models\n",
    "! ln -s ~/data/kowiki.txt ~/aiffel/bert_pretrain/data/kowiki.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "split-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-channels",
   "metadata": {},
   "source": [
    "- BERT에 사용되는 [MASK], [SEP], [CLS] 등의 주요 특수문자가 vocab에 포함되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentencepiece as spm\n",
    "# import os\n",
    "# corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "# prefix = 'ko_32000'\n",
    "# vocab_size = 32000\n",
    "\n",
    "# spm.SentencePieceTrainer.train(\n",
    "#     f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "#     \" --model_type=bpe\" +\n",
    "#     \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "#     \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "#     \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "#     \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "#     \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "#     \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disciplinary-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mv ko_32000.* ~/aiffel/bert_pretrain/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "delayed-prospect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/bert_pretrain/models/ko_32000.model': File exists\n",
      "ln: failed to create symbolic link '/aiffel/aiffel/bert_pretrain/models/ko_32000.vocab': File exists\n"
     ]
    }
   ],
   "source": [
    "! ln -s ~/data/ko_32000.model ~/aiffel/bert_pretrain/models/ko_32000.model\n",
    "! ln -s ~/data/ko_32000.vocab ~/aiffel/bert_pretrain/models/ko_32000.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수 token 7개를 제외한 나머지 tokens 들\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CLS], tokens a, [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens_org)\n",
    "\n",
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random mask를 위해서 순서를 섞음\n",
    "random.shuffle(cand_idx)\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random mask를 위해서 순서를 섞음\n",
    "random.shuffle(cand_idx)\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = []  # mask 된 값\n",
    "for index_set in cand_idx:\n",
    "    if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "          break\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "          continue\n",
    "    dice = random.random()  # 0..1 사이의 확률 값\n",
    "\n",
    "    for index in index_set:\n",
    "        masked_token = None\n",
    "        if dice < 0.8:  # 80% replace with [MASK]\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9: # 10% keep original\n",
    "            masked_token = tokens[index]\n",
    "        else:  # 10% random word\n",
    "            masked_token = random.choice(vocab_list)\n",
    "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "        tokens[index] = masked_token\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순서 정렬 및 mask_idx, mask_label 생성\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
